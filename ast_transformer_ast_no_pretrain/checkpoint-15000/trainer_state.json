{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 97.40259740259741,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.65,
      "learning_rate": 4.967532467532468e-05,
      "loss": 10.6891,
      "step": 100
    },
    {
      "epoch": 1.3,
      "learning_rate": 4.9350649350649355e-05,
      "loss": 10.4304,
      "step": 200
    },
    {
      "epoch": 1.95,
      "learning_rate": 4.902597402597403e-05,
      "loss": 10.1754,
      "step": 300
    },
    {
      "epoch": 2.6,
      "learning_rate": 4.87012987012987e-05,
      "loss": 9.9366,
      "step": 400
    },
    {
      "epoch": 3.25,
      "learning_rate": 4.8376623376623384e-05,
      "loss": 9.686,
      "step": 500
    },
    {
      "epoch": 3.9,
      "learning_rate": 4.8051948051948054e-05,
      "loss": 9.4517,
      "step": 600
    },
    {
      "epoch": 4.55,
      "learning_rate": 4.772727272727273e-05,
      "loss": 9.221,
      "step": 700
    },
    {
      "epoch": 5.19,
      "learning_rate": 4.740259740259741e-05,
      "loss": 8.9807,
      "step": 800
    },
    {
      "epoch": 5.84,
      "learning_rate": 4.707792207792208e-05,
      "loss": 8.7662,
      "step": 900
    },
    {
      "epoch": 6.49,
      "learning_rate": 4.675324675324675e-05,
      "loss": 8.5437,
      "step": 1000
    },
    {
      "epoch": 7.14,
      "learning_rate": 4.642857142857143e-05,
      "loss": 8.3339,
      "step": 1100
    },
    {
      "epoch": 7.79,
      "learning_rate": 4.6103896103896106e-05,
      "loss": 8.1488,
      "step": 1200
    },
    {
      "epoch": 8.44,
      "learning_rate": 4.577922077922078e-05,
      "loss": 7.9521,
      "step": 1300
    },
    {
      "epoch": 9.09,
      "learning_rate": 4.545454545454546e-05,
      "loss": 7.7548,
      "step": 1400
    },
    {
      "epoch": 9.74,
      "learning_rate": 4.5129870129870135e-05,
      "loss": 7.5748,
      "step": 1500
    },
    {
      "epoch": 10.39,
      "learning_rate": 4.4805194805194805e-05,
      "loss": 7.3983,
      "step": 1600
    },
    {
      "epoch": 11.04,
      "learning_rate": 4.448051948051948e-05,
      "loss": 7.2391,
      "step": 1700
    },
    {
      "epoch": 11.69,
      "learning_rate": 4.415584415584416e-05,
      "loss": 7.0804,
      "step": 1800
    },
    {
      "epoch": 12.34,
      "learning_rate": 4.3831168831168834e-05,
      "loss": 6.904,
      "step": 1900
    },
    {
      "epoch": 12.99,
      "learning_rate": 4.3506493506493503e-05,
      "loss": 6.7531,
      "step": 2000
    },
    {
      "epoch": 13.64,
      "learning_rate": 4.318181818181819e-05,
      "loss": 6.6275,
      "step": 2100
    },
    {
      "epoch": 14.29,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 6.4258,
      "step": 2200
    },
    {
      "epoch": 14.94,
      "learning_rate": 4.253246753246753e-05,
      "loss": 6.3376,
      "step": 2300
    },
    {
      "epoch": 15.58,
      "learning_rate": 4.220779220779221e-05,
      "loss": 6.2678,
      "step": 2400
    },
    {
      "epoch": 16.23,
      "learning_rate": 4.1883116883116886e-05,
      "loss": 6.1319,
      "step": 2500
    },
    {
      "epoch": 16.88,
      "learning_rate": 4.155844155844156e-05,
      "loss": 6.0156,
      "step": 2600
    },
    {
      "epoch": 17.53,
      "learning_rate": 4.123376623376624e-05,
      "loss": 5.9169,
      "step": 2700
    },
    {
      "epoch": 18.18,
      "learning_rate": 4.0909090909090915e-05,
      "loss": 5.8662,
      "step": 2800
    },
    {
      "epoch": 18.83,
      "learning_rate": 4.0584415584415584e-05,
      "loss": 5.758,
      "step": 2900
    },
    {
      "epoch": 19.48,
      "learning_rate": 4.025974025974026e-05,
      "loss": 5.7441,
      "step": 3000
    },
    {
      "epoch": 20.13,
      "learning_rate": 3.993506493506494e-05,
      "loss": 5.6503,
      "step": 3100
    },
    {
      "epoch": 20.78,
      "learning_rate": 3.9610389610389614e-05,
      "loss": 5.6343,
      "step": 3200
    },
    {
      "epoch": 21.43,
      "learning_rate": 3.928571428571429e-05,
      "loss": 5.6231,
      "step": 3300
    },
    {
      "epoch": 22.08,
      "learning_rate": 3.8961038961038966e-05,
      "loss": 5.5707,
      "step": 3400
    },
    {
      "epoch": 22.73,
      "learning_rate": 3.8636363636363636e-05,
      "loss": 5.5277,
      "step": 3500
    },
    {
      "epoch": 23.38,
      "learning_rate": 3.831168831168831e-05,
      "loss": 5.5574,
      "step": 3600
    },
    {
      "epoch": 24.03,
      "learning_rate": 3.798701298701299e-05,
      "loss": 5.4473,
      "step": 3700
    },
    {
      "epoch": 24.68,
      "learning_rate": 3.7662337662337665e-05,
      "loss": 5.4359,
      "step": 3800
    },
    {
      "epoch": 25.32,
      "learning_rate": 3.7337662337662335e-05,
      "loss": 5.4443,
      "step": 3900
    },
    {
      "epoch": 25.97,
      "learning_rate": 3.701298701298702e-05,
      "loss": 5.3941,
      "step": 4000
    },
    {
      "epoch": 26.62,
      "learning_rate": 3.668831168831169e-05,
      "loss": 5.3782,
      "step": 4100
    },
    {
      "epoch": 27.27,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 5.3478,
      "step": 4200
    },
    {
      "epoch": 27.92,
      "learning_rate": 3.603896103896104e-05,
      "loss": 5.3579,
      "step": 4300
    },
    {
      "epoch": 28.57,
      "learning_rate": 3.571428571428572e-05,
      "loss": 5.3277,
      "step": 4400
    },
    {
      "epoch": 29.22,
      "learning_rate": 3.5389610389610387e-05,
      "loss": 5.3139,
      "step": 4500
    },
    {
      "epoch": 29.87,
      "learning_rate": 3.506493506493507e-05,
      "loss": 5.2977,
      "step": 4600
    },
    {
      "epoch": 30.52,
      "learning_rate": 3.474025974025974e-05,
      "loss": 5.2285,
      "step": 4700
    },
    {
      "epoch": 31.17,
      "learning_rate": 3.4415584415584416e-05,
      "loss": 5.2306,
      "step": 4800
    },
    {
      "epoch": 31.82,
      "learning_rate": 3.409090909090909e-05,
      "loss": 5.2116,
      "step": 4900
    },
    {
      "epoch": 32.47,
      "learning_rate": 3.376623376623377e-05,
      "loss": 5.2092,
      "step": 5000
    },
    {
      "epoch": 33.12,
      "learning_rate": 3.344155844155844e-05,
      "loss": 5.1511,
      "step": 5100
    },
    {
      "epoch": 33.77,
      "learning_rate": 3.311688311688312e-05,
      "loss": 5.1691,
      "step": 5200
    },
    {
      "epoch": 34.42,
      "learning_rate": 3.27922077922078e-05,
      "loss": 5.1218,
      "step": 5300
    },
    {
      "epoch": 35.06,
      "learning_rate": 3.246753246753247e-05,
      "loss": 5.0895,
      "step": 5400
    },
    {
      "epoch": 35.71,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 5.0664,
      "step": 5500
    },
    {
      "epoch": 36.36,
      "learning_rate": 3.181818181818182e-05,
      "loss": 4.9992,
      "step": 5600
    },
    {
      "epoch": 37.01,
      "learning_rate": 3.14935064935065e-05,
      "loss": 5.0394,
      "step": 5700
    },
    {
      "epoch": 37.66,
      "learning_rate": 3.1168831168831166e-05,
      "loss": 5.0253,
      "step": 5800
    },
    {
      "epoch": 38.31,
      "learning_rate": 3.084415584415585e-05,
      "loss": 4.9818,
      "step": 5900
    },
    {
      "epoch": 38.96,
      "learning_rate": 3.051948051948052e-05,
      "loss": 4.9893,
      "step": 6000
    },
    {
      "epoch": 39.61,
      "learning_rate": 3.01948051948052e-05,
      "loss": 4.9213,
      "step": 6100
    },
    {
      "epoch": 40.26,
      "learning_rate": 2.9870129870129872e-05,
      "loss": 4.9261,
      "step": 6200
    },
    {
      "epoch": 40.91,
      "learning_rate": 2.954545454545455e-05,
      "loss": 4.8772,
      "step": 6300
    },
    {
      "epoch": 41.56,
      "learning_rate": 2.922077922077922e-05,
      "loss": 4.8679,
      "step": 6400
    },
    {
      "epoch": 42.21,
      "learning_rate": 2.8896103896103898e-05,
      "loss": 4.8924,
      "step": 6500
    },
    {
      "epoch": 42.86,
      "learning_rate": 2.857142857142857e-05,
      "loss": 4.803,
      "step": 6600
    },
    {
      "epoch": 43.51,
      "learning_rate": 2.824675324675325e-05,
      "loss": 4.7946,
      "step": 6700
    },
    {
      "epoch": 44.16,
      "learning_rate": 2.792207792207792e-05,
      "loss": 4.7885,
      "step": 6800
    },
    {
      "epoch": 44.81,
      "learning_rate": 2.75974025974026e-05,
      "loss": 4.7136,
      "step": 6900
    },
    {
      "epoch": 45.45,
      "learning_rate": 2.7272727272727273e-05,
      "loss": 4.7282,
      "step": 7000
    },
    {
      "epoch": 46.1,
      "learning_rate": 2.694805194805195e-05,
      "loss": 4.727,
      "step": 7100
    },
    {
      "epoch": 46.75,
      "learning_rate": 2.6623376623376623e-05,
      "loss": 4.706,
      "step": 7200
    },
    {
      "epoch": 47.4,
      "learning_rate": 2.62987012987013e-05,
      "loss": 4.6716,
      "step": 7300
    },
    {
      "epoch": 48.05,
      "learning_rate": 2.5974025974025972e-05,
      "loss": 4.6683,
      "step": 7400
    },
    {
      "epoch": 48.7,
      "learning_rate": 2.5649350649350652e-05,
      "loss": 4.6057,
      "step": 7500
    },
    {
      "epoch": 49.35,
      "learning_rate": 2.5324675324675325e-05,
      "loss": 4.6125,
      "step": 7600
    },
    {
      "epoch": 50.0,
      "learning_rate": 2.5e-05,
      "loss": 4.633,
      "step": 7700
    },
    {
      "epoch": 50.65,
      "learning_rate": 2.4675324675324678e-05,
      "loss": 4.6033,
      "step": 7800
    },
    {
      "epoch": 51.3,
      "learning_rate": 2.435064935064935e-05,
      "loss": 4.5976,
      "step": 7900
    },
    {
      "epoch": 51.95,
      "learning_rate": 2.4025974025974027e-05,
      "loss": 4.5291,
      "step": 8000
    },
    {
      "epoch": 52.6,
      "learning_rate": 2.3701298701298703e-05,
      "loss": 4.4954,
      "step": 8100
    },
    {
      "epoch": 53.25,
      "learning_rate": 2.3376623376623376e-05,
      "loss": 4.5105,
      "step": 8200
    },
    {
      "epoch": 53.9,
      "learning_rate": 2.3051948051948053e-05,
      "loss": 4.4426,
      "step": 8300
    },
    {
      "epoch": 54.55,
      "learning_rate": 2.272727272727273e-05,
      "loss": 4.46,
      "step": 8400
    },
    {
      "epoch": 55.19,
      "learning_rate": 2.2402597402597402e-05,
      "loss": 4.468,
      "step": 8500
    },
    {
      "epoch": 55.84,
      "learning_rate": 2.207792207792208e-05,
      "loss": 4.4387,
      "step": 8600
    },
    {
      "epoch": 56.49,
      "learning_rate": 2.1753246753246752e-05,
      "loss": 4.3886,
      "step": 8700
    },
    {
      "epoch": 57.14,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 4.4023,
      "step": 8800
    },
    {
      "epoch": 57.79,
      "learning_rate": 2.1103896103896105e-05,
      "loss": 4.3887,
      "step": 8900
    },
    {
      "epoch": 58.44,
      "learning_rate": 2.077922077922078e-05,
      "loss": 4.3809,
      "step": 9000
    },
    {
      "epoch": 59.09,
      "learning_rate": 2.0454545454545457e-05,
      "loss": 4.3518,
      "step": 9100
    },
    {
      "epoch": 59.74,
      "learning_rate": 2.012987012987013e-05,
      "loss": 4.3656,
      "step": 9200
    },
    {
      "epoch": 60.39,
      "learning_rate": 1.9805194805194807e-05,
      "loss": 4.3448,
      "step": 9300
    },
    {
      "epoch": 61.04,
      "learning_rate": 1.9480519480519483e-05,
      "loss": 4.3257,
      "step": 9400
    },
    {
      "epoch": 61.69,
      "learning_rate": 1.9155844155844156e-05,
      "loss": 4.3109,
      "step": 9500
    },
    {
      "epoch": 62.34,
      "learning_rate": 1.8831168831168833e-05,
      "loss": 4.2629,
      "step": 9600
    },
    {
      "epoch": 62.99,
      "learning_rate": 1.850649350649351e-05,
      "loss": 4.2887,
      "step": 9700
    },
    {
      "epoch": 63.64,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 4.2508,
      "step": 9800
    },
    {
      "epoch": 64.29,
      "learning_rate": 1.785714285714286e-05,
      "loss": 4.2912,
      "step": 9900
    },
    {
      "epoch": 64.94,
      "learning_rate": 1.7532467532467535e-05,
      "loss": 4.2116,
      "step": 10000
    },
    {
      "epoch": 65.58,
      "learning_rate": 1.7207792207792208e-05,
      "loss": 4.2108,
      "step": 10100
    },
    {
      "epoch": 66.23,
      "learning_rate": 1.6883116883116884e-05,
      "loss": 4.2333,
      "step": 10200
    },
    {
      "epoch": 66.88,
      "learning_rate": 1.655844155844156e-05,
      "loss": 4.1396,
      "step": 10300
    },
    {
      "epoch": 67.53,
      "learning_rate": 1.6233766233766234e-05,
      "loss": 4.1505,
      "step": 10400
    },
    {
      "epoch": 68.18,
      "learning_rate": 1.590909090909091e-05,
      "loss": 4.1788,
      "step": 10500
    },
    {
      "epoch": 68.83,
      "learning_rate": 1.5584415584415583e-05,
      "loss": 4.1774,
      "step": 10600
    },
    {
      "epoch": 69.48,
      "learning_rate": 1.525974025974026e-05,
      "loss": 4.1819,
      "step": 10700
    },
    {
      "epoch": 70.13,
      "learning_rate": 1.4935064935064936e-05,
      "loss": 4.1655,
      "step": 10800
    },
    {
      "epoch": 70.78,
      "learning_rate": 1.461038961038961e-05,
      "loss": 4.1601,
      "step": 10900
    },
    {
      "epoch": 71.43,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 4.0667,
      "step": 11000
    },
    {
      "epoch": 72.08,
      "learning_rate": 1.396103896103896e-05,
      "loss": 4.0896,
      "step": 11100
    },
    {
      "epoch": 72.73,
      "learning_rate": 1.3636363636363637e-05,
      "loss": 4.0708,
      "step": 11200
    },
    {
      "epoch": 73.38,
      "learning_rate": 1.3311688311688311e-05,
      "loss": 4.068,
      "step": 11300
    },
    {
      "epoch": 74.03,
      "learning_rate": 1.2987012987012986e-05,
      "loss": 4.0562,
      "step": 11400
    },
    {
      "epoch": 74.68,
      "learning_rate": 1.2662337662337662e-05,
      "loss": 4.0654,
      "step": 11500
    },
    {
      "epoch": 75.32,
      "learning_rate": 1.2337662337662339e-05,
      "loss": 4.1388,
      "step": 11600
    },
    {
      "epoch": 75.97,
      "learning_rate": 1.2012987012987014e-05,
      "loss": 4.0226,
      "step": 11700
    },
    {
      "epoch": 76.62,
      "learning_rate": 1.1688311688311688e-05,
      "loss": 4.0427,
      "step": 11800
    },
    {
      "epoch": 77.27,
      "learning_rate": 1.1363636363636365e-05,
      "loss": 4.0479,
      "step": 11900
    },
    {
      "epoch": 77.92,
      "learning_rate": 1.103896103896104e-05,
      "loss": 4.0113,
      "step": 12000
    },
    {
      "epoch": 78.57,
      "learning_rate": 1.0714285714285714e-05,
      "loss": 3.9889,
      "step": 12100
    },
    {
      "epoch": 79.22,
      "learning_rate": 1.038961038961039e-05,
      "loss": 4.0435,
      "step": 12200
    },
    {
      "epoch": 79.87,
      "learning_rate": 1.0064935064935065e-05,
      "loss": 3.9916,
      "step": 12300
    },
    {
      "epoch": 80.52,
      "learning_rate": 9.740259740259742e-06,
      "loss": 3.9538,
      "step": 12400
    },
    {
      "epoch": 81.17,
      "learning_rate": 9.415584415584416e-06,
      "loss": 4.0481,
      "step": 12500
    },
    {
      "epoch": 81.82,
      "learning_rate": 9.090909090909091e-06,
      "loss": 4.0001,
      "step": 12600
    },
    {
      "epoch": 82.47,
      "learning_rate": 8.766233766233767e-06,
      "loss": 3.9543,
      "step": 12700
    },
    {
      "epoch": 83.12,
      "learning_rate": 8.441558441558442e-06,
      "loss": 3.9997,
      "step": 12800
    },
    {
      "epoch": 83.77,
      "learning_rate": 8.116883116883117e-06,
      "loss": 3.9913,
      "step": 12900
    },
    {
      "epoch": 84.42,
      "learning_rate": 7.792207792207792e-06,
      "loss": 4.001,
      "step": 13000
    },
    {
      "epoch": 85.06,
      "learning_rate": 7.467532467532468e-06,
      "loss": 3.9902,
      "step": 13100
    },
    {
      "epoch": 85.71,
      "learning_rate": 7.142857142857143e-06,
      "loss": 3.9524,
      "step": 13200
    },
    {
      "epoch": 86.36,
      "learning_rate": 6.818181818181818e-06,
      "loss": 3.9536,
      "step": 13300
    },
    {
      "epoch": 87.01,
      "learning_rate": 6.493506493506493e-06,
      "loss": 3.9278,
      "step": 13400
    },
    {
      "epoch": 87.66,
      "learning_rate": 6.168831168831169e-06,
      "loss": 3.9909,
      "step": 13500
    },
    {
      "epoch": 88.31,
      "learning_rate": 5.844155844155844e-06,
      "loss": 3.9148,
      "step": 13600
    },
    {
      "epoch": 88.96,
      "learning_rate": 5.51948051948052e-06,
      "loss": 3.9456,
      "step": 13700
    },
    {
      "epoch": 89.61,
      "learning_rate": 5.194805194805195e-06,
      "loss": 3.9288,
      "step": 13800
    },
    {
      "epoch": 90.26,
      "learning_rate": 4.870129870129871e-06,
      "loss": 3.9071,
      "step": 13900
    },
    {
      "epoch": 90.91,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 3.9292,
      "step": 14000
    },
    {
      "epoch": 91.56,
      "learning_rate": 4.220779220779221e-06,
      "loss": 3.9385,
      "step": 14100
    },
    {
      "epoch": 92.21,
      "learning_rate": 3.896103896103896e-06,
      "loss": 3.928,
      "step": 14200
    },
    {
      "epoch": 92.86,
      "learning_rate": 3.5714285714285714e-06,
      "loss": 3.9011,
      "step": 14300
    },
    {
      "epoch": 93.51,
      "learning_rate": 3.2467532467532465e-06,
      "loss": 3.9609,
      "step": 14400
    },
    {
      "epoch": 94.16,
      "learning_rate": 2.922077922077922e-06,
      "loss": 3.9127,
      "step": 14500
    },
    {
      "epoch": 94.81,
      "learning_rate": 2.5974025974025976e-06,
      "loss": 3.9056,
      "step": 14600
    },
    {
      "epoch": 95.45,
      "learning_rate": 2.2727272727272728e-06,
      "loss": 3.9076,
      "step": 14700
    },
    {
      "epoch": 96.1,
      "learning_rate": 1.948051948051948e-06,
      "loss": 3.9004,
      "step": 14800
    },
    {
      "epoch": 96.75,
      "learning_rate": 1.6233766233766232e-06,
      "loss": 3.9014,
      "step": 14900
    },
    {
      "epoch": 97.4,
      "learning_rate": 1.2987012987012988e-06,
      "loss": 3.8853,
      "step": 15000
    }
  ],
  "max_steps": 15400,
  "num_train_epochs": 100,
  "total_flos": 122678142576552.0,
  "trial_name": null,
  "trial_params": null
}
